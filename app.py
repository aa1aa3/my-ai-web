import streamlit as st
import google.generativeai as genai
from datetime import datetime
import sys

# === ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØµÙØ­Ø© ===
st.set_page_config(
    page_title="Gemini Pro AI - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === Ø¬Ù„Ø¨ Ù…ÙØªØ§Ø­ API ===
def get_api_key():
    try:
        if hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
            return st.secrets["GEMINI_API_KEY"]
    except:
        pass
    
    import os
    env_key = os.environ.get("GEMINI_API_KEY")
    if env_key:
        return env_key
    
    return "AIzaSyD5pmXKOY-qhd2k8DeJSeq-V4fgnT1zdqs"

# === ØªÙ‡ÙŠØ¦Ø© Gemini ===
@st.cache_resource
def init_gemini():
    try:
        api_key = get_api_key()
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        model.generate_content("test", generation_config={"max_output_tokens": 1})
        return True, "âœ… API Ù…ÙØ¹Ù„ Ø¨Ù†Ø¬Ø§Ø­"
    except Exception as e:
        return False, f"âŒ Ø®Ø·Ø£ ÙÙŠ API: {str(e)}"

# === ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ===
with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ..."):
    init_result, init_message = init_gemini()

# === Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ===
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
    
    st.subheader("ğŸ”§ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…")
    st.info(init_message)
    python_version = sys.version.split()[0]
    st.metric("Ø¥ØµØ¯Ø§Ø± Python", python_version)
    
    st.subheader("ğŸ¤– Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    model_choice = st.selectbox(
        "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
        [
            "gemini-1.5-pro-latest",
            "gemini-1.5-flash-latest", 
            "gemini-1.0-pro-latest",
            "gemini-pro"
        ],
        index=1
    )
    
    st.subheader("ğŸ›ï¸ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…ØªÙ‚Ø¯Ù…Ø©")
    col1, col2 = st.columns(2)
    with col1:
        temperature = st.slider("Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹", 0.0, 2.0, 0.7, 0.1)
    with col2:
        max_tokens = st.number_input("Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø±Ù…ÙˆØ²", 100, 8192, 2000)
    
    top_p = st.slider("Top-P", 0.0, 1.0, 0.95, 0.05)
    top_k = st.slider("Top-K", 1, 40, 40, 1)
    
    st.subheader("ğŸ” Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
    safety_settings = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†", value=True)
    streaming = st.checkbox("Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Streaming)", value=False)
    
    st.markdown("---")
    with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ©"):
        st.code(f"""
Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_choice}
Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {temperature}
Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰: {max_tokens} Ø±Ù…Ø²
Top-P: {top_p}
Top-K: {top_k}
Ø§Ù„Ù…ÙØªØ§Ø­: {'****' + get_api_key()[-4:] if init_result else 'ØºÙŠØ± Ù…ÙØ¹Ù„'}
        """)

# === Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ===
st.title("ğŸš€ Gemini AI - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
st.markdown("""
<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;'>
<h3 style='color: white;'>Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:</h3>
<ul>
<li>Ø¯Ø¹Ù… Python 3.11+</li>
<li>Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ØªÙˆÙ„ÙŠØ¯ Ù…ØªÙ‚Ø¯Ù…Ø© (Temperature, Top-P, Top-K)</li>
<li>Ø£Ø±Ø¨Ø¹Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Gemini</li>
<li>Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ù…ÙØ§ØªÙŠØ­ Ø¢Ù…Ù†</li>
<li>Ù…Ø±Ø§Ù‚Ø¨Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…</li>
</ul>
</div>
""", unsafe_allow_html=True)

# === Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ===
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'model_config' not in st.session_state:
    st.session_state.model_config = {
        "temperature": temperature,
        "max_output_tokens": max_tokens,
        "top_p": top_p,
        "top_k": top_k
    }

# === Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ===
st.subheader("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø°ÙƒÙŠØ©")

# Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
    if not init_result:
        st.error("Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ÙØ¹Ù„. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API.")
        st.stop()
    
    # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
    with st.chat_message("assistant"):
        with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯..."):
            try:
                generation_config = {
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                    "top_p": top_p,
                    "top_k": top_k,
                }
                
                safety_config = None
                if safety_settings:
                    safety_config = [
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    ]
                
                model = genai.GenerativeModel(
                    model_name=model_choice,
                    generation_config=generation_config,
                    safety_settings=safety_config
                )
                
                response = model.generate_content(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response.text
                })
                
            except Exception as e:
                error_msg = f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"âš ï¸ {error_msg}"
                })

# === Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ… ===
st.markdown("---")
col1, col2, col3, col4 = st.columns(4)

with col1:
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©", use_container_width=True):
        st.rerun()

with col2:
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

with col3:
    if st.button("ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…", use_container_width=True):
        st.info(f"""
        Ø­Ø§Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {init_message}
        Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„: {len(st.session_state.messages)}
        Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ: {model_choice}
        Ø¥ØµØ¯Ø§Ø± Python: {python_version}
        """)

with col4:
    if st.session_state.messages:
        chat_text = "\n\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
        st.download_button(
            label="ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            data=chat_text,
            file_name=f"gemini_chat_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
            mime="text/plain",
            use_container_width=True
        )

# === ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø© ===
st.markdown("---")
footer = f"""
<div style='text-align: center; color: #666; padding: 20px;'>
<p>ğŸš€ Gemini AI Pro | Python {python_version} | Model: {model_choice} | Tokens: {max_tokens}</p>
<p>Â© {datetime.now().year} - ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit & Google Gemini API</p>
</div>
"""
st.markdown(footer, unsafe_allow_html=True)# ============================================
st.title("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Gemini AI")

# Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù…Ø®ÙÙŠ (ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„)
with st.sidebar:
    st.markdown("### Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©")
    model_type = st.radio(
        "Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
        ["gemini-1.5-flash", "gemini-1.5-pro"]
    )
    if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø·"):
        st.session_state.chat_history = []
        st.rerun()

# ============================================
# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø¨Ø¯ÙˆÙ† ØªØ¹Ù‚ÙŠØ¯)
# ============================================
st.subheader("ğŸ’¬ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
if st.session_state.chat_history:
    for msg in st.session_state.chat_history:
        role_icon = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
        st.markdown(f"**{role_icon} {msg['role'].title()}:** {msg['content']}")
        st.markdown("---")

# ============================================
# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø©)
# ============================================
user_input = st.text_area("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§:", height=100)

col1, col2 = st.columns(2)
with col1:
    send_btn = st.button("ğŸš€ Ø¥Ø±Ø³Ø§Ù„", type="primary", use_container_width=True)
with col2:
    clear_btn = st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True)

if clear_btn:
    st.session_state.chat_history = []
    st.rerun()

if send_btn and user_input:
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
        try:
            # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_input
            })
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
            model = genai.GenerativeModel(model_type)
            response = model.generate_content(user_input)
            
            # Ø¥Ø¶Ø§ÙØ© Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response.text
            })
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø¹Ù†Ø§ÙŠØ©
            time.sleep(0.5)  # ØªØ£Ø®ÙŠØ± Ù‚ØµÙŠØ±
            st.rerun()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
            st.info("Ø¬Ø±Ø¨ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø© (F5)")

# ============================================
# Ù†ØµØ§Ø¦Ø­ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
# ============================================
with st.expander("ğŸ› ï¸ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø§Ù„Ø®Ø·Ø£:"):
    st.markdown("""
    1. **Ø§ÙØªØ­ Ù†Ø§ÙØ°Ø© Ù…ØªØµÙØ­ Ø®Ø§ØµØ©** (Incognito)
    2. **ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ù†ÙˆØ§Ù† URL Ø§Ù„ØµØ­ÙŠØ­**: [https://my-ai-web.streamlit.app](https://my-ai-web.streamlit.app)
    3. **Ø¬Ø±Ø¨ Ù…ØªØµÙØ­Ø§Ù‹ Ø¢Ø®Ø±**: Chrome / Firefox / Edge
    4. **ØªØ¹Ø·ÙŠÙ„ Ø¥Ø¶Ø§ÙØ§Øª Ø§Ù„Ù…ØªØµÙØ­** Ù…Ø¤Ù‚ØªØ§Ù‹
    5. **Ø§Ù†ØªØ¸Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚** Ø«Ù… Ø¬Ø±Ø¨ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
    """)

# ============================================
# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
# ============================================
st.markdown("---")
st.caption("âœ¨ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø± | Gemini API | Streamlit")# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
st.subheader("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«ØªÙƒ Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

# ØªÙ‡ÙŠØ¦Ø© history ÙÙŠ session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...")

if user_input:
    # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ®
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    
    # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø¯
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” ÙŠÙÙƒØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
            try:
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                generation_config = {
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                }
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                model = genai.GenerativeModel(
                    model_name=model_choice,
                    generation_config=generation_config
                )
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                response = model.generate_content(user_input)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯
                st.markdown(response.text)
                
                # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
                st.session_state.chat_history.append({
                    "role": "assistant", 
                    "content": response.text
                })
                
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
                st.info("Ø¬Ø±Ø¨ ØªØºÙŠÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©")

# Ù…ÙŠØ²Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³ÙÙ„ÙŠ
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()

with col2:
    if st.button("ğŸ“‹ Ù†Ø³Ø® Ø¢Ø®Ø± Ø±Ø¯", use_container_width=True):
        if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "assistant":
            st.code(st.session_state.chat_history[-1]["content"])

with col3:
    st.download_button(
        label="ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
        data="\n\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.chat_history]),
        file_name=f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain",
        use_container_width=True
    )

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.caption("âš¡ Powered by Google Gemini API | ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit")boot Ø¥Ø¬Ø¨Ø§Ø±ÙŠ.")
